Overview of the Ask

Input is an MP4 file containing a conversation between two people.
Need to analyze the audio stream of the MP4 to detect spoken credit card numbers (format: XXXX-XXXX-XXXX-XXXX or similar).
Extract the timestamp(s) when such numbers are spoken.
Mute or remove audio from the MP4 file in those specific segments.
Output the redacted MP4 file (with muted sections) and a report/log of the detected timestamps.
üõ†Ô∏è Types of Solutions to Automate the Workflow

Solution Type

Tools/Technologies

Description

Speech-to-Text + Regex Filter

OpenAI Whisper, Google STT, AWS Transcribe + RegEx

Transcribe audio, then scan transcript for credit card patterns.

Real-time Audio Pattern Detection

Vosk, DeepSpeech, Kaldi + pattern matching

Detect number-like sequences during streaming transcription.

ML Model for Number Detection

Custom ML/NLP model trained to detect spoken credit cards

Specialized model trained to identify credit card numbers in speech.

Media Processing Pipeline

FFmpeg + Python/Pydub + STT

End-to-end automation: transcribe ‚Üí detect ‚Üí extract timestamps ‚Üí mute video.

SaaS Workflow Automation

Zapier + Speech AI APIs + Media APIs

Low-code platform to automate detection + redaction using available services.

‚ö†Ô∏è Challenges We Might Face

Accuracy of Speech Recognition:
Credit card numbers may be misrecognized depending on accent, clarity, or noise.
Spoken digits may not follow a consistent format (e.g., "four zero five five" vs "four oh five five").
Speaker Diarization:
Differentiating between speakers may be required to determine who is speaking the number.
Not all STT engines support reliable diarization.
Time Alignment Granularity:
Mapping transcript tokens to precise timestamps (down to a second or sub-second) is critical for accurate muting.
Credit Card Format Variation:
Spoken numbers may not include dashes or might be grouped differently.
Must handle ‚Äúfour-two-zero-six triple five‚Äù or ‚Äúfour two zero six five five five five‚Ä¶‚Äù
Audio Redaction Without Desync:
Muting the correct portions of audio without affecting video sync.
Over-muting might result in loss of important non-sensitive conversation.
Data Privacy and Compliance:
Ensuring that sensitive data is not stored or leaked during processing.
Scalability:
For multiple files or long videos, performance and batch processing become important.
 

 

 

Great! Below is a proposed architecture followed by a sample Python code pipeline that uses:

FFmpeg to extract audio and later mute video segments
Whisper or any STT to transcribe speech to text with timestamps
Regex to detect credit card-like numbers
Pydub to identify and mute audio sections
Final re-muxing with FFmpeg to replace the audio in the video
üß± Architecture: Media Processing Pipeline
Steps:
Extract Audio from MP4
Use FFmpeg to extract audio to .wav (recommended for STT engines)
Transcribe Audio
Use OpenAI Whisper or another STT to convert audio to text with word-level timestamps
Detect Credit Card Numbers
Apply regex or pattern logic to identify credit card numbers in the transcript
Get start and end timestamps for each number spoken
Mute Audio Sections
Use Pydub or FFmpeg to mute the corresponding audio segments
Replace Audio in MP4
Mux the muted audio back into the original MP4 using FFmpeg
 

 

 

 

 

import os

import re

from pydub import AudioSegment

import whisper

from datetime import timedelta

 

# Step 1: Extract audio from MP4

def extract_audio(mp4_file, wav_file):

    os.system(f"ffmpeg -y -i \"{mp4_file}\" -ac 1 -ar 16000 -vn \"{wav_file}\"")

 

# Step 2: Transcribe using Whisper

def transcribe_audio(wav_file):

    model = whisper.load_model("base")

    result = model.transcribe(wav_file, word_timestamps=True)

    return result['segments']

 

# Step 3: Detect credit card patterns (16-digit sequences)

def detect_cc_numbers(segments):

    cc_pattern = re.compile(r'(\d[\d ]{11,19})')  # loose match for spoken card numbers

    mute_times = []

 

    for seg in segments:

        text = seg['text']

        match = cc_pattern.search(text.replace('-', '').replace('\n', ''))

        if match:

            start = seg['start']

            end = seg['end']

            mute_times.append((start, end))

 

    return mute_times

 

# Step 4: Mute segments using Pydub

def mute_audio(input_wav, mute_times, output_wav):

    audio = AudioSegment.from_wav(input_wav)

 

    for start, end in mute_times:

        start_ms = int(start * 1000)

        end_ms = int(end * 1000)

        silence = AudioSegment.silent(duration=(end_ms - start_ms))

        audio = audio[:start_ms] + silence + audio[end_ms:]

 

    audio.export(output_wav, format="wav")

 

# Step 5: Replace original audio with muted audio in MP4

def mux_muted_audio_back(original_mp4, muted_wav, output_mp4):

    os.system(f"ffmpeg -y -i \"{original_mp4}\" -i \"{muted_wav}\" -c:v copy -map 0:v:0 -map 1:a:0 -shortest \"{output_mp4}\"")

 

# Pipeline runner

def process_video(mp4_path):

    audio_wav = "temp_audio.wav"

    muted_audio = "muted_audio.wav"

    redacted_mp4 = "redacted_output.mp4"

 

    extract_audio(mp4_path, audio_wav)

    segments = transcribe_audio(audio_wav)

    mute_ranges = detect_cc_numbers(segments)

    mute_audio(audio_wav, mute_ranges, muted_audio)

    mux_muted_audio_back(mp4_path, muted_audio, redacted_mp4)

 

    print("Redacted video saved as:", redacted_mp4)

 

# Example usage

process_video("conversation.mp4")

 

 

 

 

Dependencies

Install these first:

bash

CopyEdit

pip install pydub openai-whisper ffmpeg-python

Also, ensure ffmpeg is installed and available in your system path.

üì¶ Output

Redacted MP4: redacted_output.mp4
Log of redacted timestamps: You can also log mute_times into a JSON or text file if needed.
 

https://media.licdn.com/dms/image/v2/D5622AQGV7ETf_KHxkg/feedshare-shrink_2048_1536/B56ZVPjmWqHoAs-/0/1740796488514?e=1749081600&v=beta&t=C3VfcPsM3SzqtQK1KgB2k_GWyt_vG7Kahbq0xVfDcPY

 

 

 

https://media.licdn.com/dms/image/v2/D5622AQHhAT6n9LnOwQ/feedshare-shrink_2048_1536/feedshare-shrink_2048_1536/0/1731478759149?e=1749081600&v=beta&t=GY5H2jbr4fbHV2tizVOSR11GYo6QwOK_EZN448aFTmw

